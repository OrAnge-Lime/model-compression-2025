{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74d7c97-d6b5-493a-b300-0b136b4829c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (24.3.25)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.63.0)\n",
      "Collecting h5py>=2.9.0 (from tensorflow)\n",
      "  Downloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow)\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting numpy<=1.24.3,>=1.22 (from tensorflow)\n",
      "  Downloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (75.3.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow)\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.4.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (7.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.18.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Downloading tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.6/479.6 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Downloading wrapt-1.17.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85 kB)\n",
      "Installing collected packages: libclang, wrapt, typing-extensions, tensorflow-io-gcs-filesystem, tensorflow-estimator, protobuf, opt-einsum, numpy, keras, google-pasta, gast, astunparse, h5py, tensorboard, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.26.1\n",
      "    Uninstalling protobuf-5.26.1:\n",
      "      Successfully uninstalled protobuf-5.26.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.14.0\n",
      "    Uninstalling tensorboard-2.14.0:\n",
      "      Successfully uninstalled tensorboard-2.14.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sqlalchemy 2.0.30 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic 2.7.1 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic-core 2.18.2 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "torch 2.3.0+cu121 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed astunparse-1.6.3 gast-0.4.0 google-pasta-0.2.0 h5py-3.11.0 keras-2.13.1 libclang-18.1.1 numpy-1.24.3 opt-einsum-3.4.0 protobuf-4.25.6 tensorboard-2.13.0 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.34.0 typing-extensions-4.5.0 wrapt-1.17.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "# !pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9b24e1b-0795-4176-9188-e34d632c690e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 11:32:36.916365: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-03 11:32:36.954243: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-03 11:32:36.954971: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-03 11:32:37.614894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_model_optimization.python.core.keras.compat import keras\n",
    "\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from model_profiler import model_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4438396-f390-45ee-b94a-5782174be810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 11:32:48.944791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-03 11:32:49.159229: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.2882 - accuracy: 0.9183 - val_loss: 0.1256 - val_accuracy: 0.9635\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.1182 - accuracy: 0.9662 - val_loss: 0.0850 - val_accuracy: 0.9767\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0871 - accuracy: 0.9740 - val_loss: 0.0702 - val_accuracy: 0.9818\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0714 - accuracy: 0.9789 - val_loss: 0.0665 - val_accuracy: 0.9830\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0614 - accuracy: 0.9813 - val_loss: 0.0593 - val_accuracy: 0.9845\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.0540 - accuracy: 0.9839 - val_loss: 0.0631 - val_accuracy: 0.9842\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.0487 - accuracy: 0.9848 - val_loss: 0.0583 - val_accuracy: 0.9835\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.0570 - val_accuracy: 0.9848\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 13s 7ms/step - loss: 0.0393 - accuracy: 0.9880 - val_loss: 0.0554 - val_accuracy: 0.9853\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0363 - accuracy: 0.9889 - val_loss: 0.0570 - val_accuracy: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7934843eab50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images  = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "    keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation=tf.nn.relu),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    validation_split=0.1,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "240d869e-dfb8-4440-9eea-5cb4289e4f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 12)        120       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 12)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2028)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                20290     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20410 (79.73 KB)\n",
      "Trainable params: 20410 (79.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c56487-5343-4d2e-a833-c82a85eab05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model Profile                    | Value         | Unit    |\n",
      "|----------------------------------|---------------|---------|\n",
      "| Selected GPUs                    | None Detected | GPU IDs |\n",
      "| No. of FLOPs                     | 0.0           | BFLOPs  |\n",
      "| GPU Memory Requirement           | 0.0062        | GB      |\n",
      "| Model Parameters                 | 0.0204        | Million |\n",
      "| Memory Required by Model Weights | 0.0779        | MB      |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 11:35:10.583619: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-03 11:35:10.589089: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "print(model_profiler(model, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59b8df7f-476b-44d1-a2f4-7ef60b8d08d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9818000197410583\n",
      "Saving model to:  /src/init_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/2115648425.py:8: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  keras.models.save_model(model, keras_file, include_optimizer=False)\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "keras_file = '/src/init_model.h5'\n",
    "print('Saving model to: ', keras_file)\n",
    "keras.models.save_model(model, keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a90c7376-e952-4a09-9519-5cd45c9541fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d/kernel:0 [[[[ 0.64077187  0.43250504 -0.83814985  0.07134694  0.0628445\n",
      "    -0.46368307  0.37904808  0.8151185  -0.04636772  0.278506\n",
      "    -1.09907     0.15333119]]\n",
      "\n",
      "  [[ 0.9119164   0.2704301  -0.19328047 -0.70747447  0.23428154\n",
      "     0.3691828   0.34915763  0.5253925   0.31428316  0.3000083\n",
      "    -0.84211934  0.1376472 ]]\n",
      "\n",
      "  [[ 0.92826295 -1.0867482   0.08003949 -0.9335634   0.37558675\n",
      "     0.42365554 -0.07505465 -1.0386263  -0.77900094 -0.44590425\n",
      "    -0.14758453 -0.09695109]]]\n",
      "\n",
      "\n",
      " [[[-0.29868412  0.7922094  -0.5168316   0.7944505   0.07161665\n",
      "     0.38733372 -0.08406575  1.0821877  -0.13897736 -0.30250108\n",
      "    -0.6132253   0.3301399 ]]\n",
      "\n",
      "  [[ 0.39916244  0.19270536  0.01370717  0.05316766  0.14108358\n",
      "     0.40726933 -0.141179    0.17478572 -0.5516148   0.42308643\n",
      "     0.6352827   0.49112305]]\n",
      "\n",
      "  [[ 0.5651289  -1.1630152  -0.02701709 -0.20516421 -0.27427202\n",
      "    -0.35407698 -0.19408044 -1.2392026  -0.28797403  0.08683338\n",
      "     0.86733365  0.19957688]]]\n",
      "\n",
      "\n",
      " [[[-1.4549811   0.74576855  0.7375761   0.44580543  0.29609725\n",
      "     0.32540795 -0.13276379 -0.03565762 -0.60003096 -0.590632\n",
      "    -0.11738607 -0.86712795]]\n",
      "\n",
      "  [[-1.6224266   0.2811283   0.7809335   0.33940095  0.1818529\n",
      "    -0.27245572  0.28593114 -1.5311601  -0.23601231  0.41792774\n",
      "     0.3830698  -0.43648624]]\n",
      "\n",
      "  [[-1.4115425  -0.57166904 -0.18819875  0.2507739   0.00609764\n",
      "    -0.29482982  0.45202774 -1.2294492   0.0109726   0.14237903\n",
      "    -0.00189922  0.5842859 ]]]]\n",
      "conv2d/bias:0 [-0.00937476 -0.16047636 -0.00884279 -0.1406883  -0.50637954 -0.29607904\n",
      " -0.42635387 -0.00376729  0.29789737 -0.2601242  -0.05612424 -0.19411802]\n",
      "dense/kernel:0 [[ 1.4008361e-01  2.5361079e-01 -4.3695351e-01 ...  2.2502510e-01\n",
      "  -3.9156973e-02  2.7141213e-01]\n",
      " [-4.2864278e-02  3.4079474e-04  5.2614056e-02 ...  3.5158657e-02\n",
      "  -1.1227222e-01 -4.8721578e-02]\n",
      " [ 3.2207948e-01  3.0527863e-01 -4.2667672e-01 ...  1.2797336e-01\n",
      "  -1.7028368e-01  3.3041781e-01]\n",
      " ...\n",
      " [-9.9831179e-02 -1.4935304e-01  1.7463878e-01 ... -1.1072149e-01\n",
      "  -1.3589330e-01 -8.0359958e-02]\n",
      " [ 2.4848150e-02  3.0155692e-01 -1.9966803e-01 ...  9.0616897e-02\n",
      "   3.1457122e-02  4.2233676e-02]\n",
      " [-7.2722621e-02 -1.2868321e-01 -5.6567810e-02 ... -5.8931518e-02\n",
      "  -1.9418220e-01 -1.3988857e-01]]\n",
      "dense/bias:0 [ 0.01872514  0.14286542  0.01087739 -0.04219219 -0.05122808  0.04067702\n",
      " -0.01219259  0.02556597 -0.06718774 -0.02638319]\n"
     ]
    }
   ],
   "source": [
    "for w in model.weights:\n",
    "    print(w.name, w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f494184a-c257-4f01-a6fe-e2854fecb44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_reshape (ClusterWe  (None, 28, 28, 1)         0         \n",
      " ights)                                                          \n",
      "                                                                 \n",
      " cluster_conv2d (ClusterWei  (None, 26, 26, 12)        236       \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      " cluster_max_pooling2d (Clu  (None, 13, 13, 12)        0         \n",
      " sterWeights)                                                    \n",
      "                                                                 \n",
      " cluster_flatten (ClusterWe  (None, 2028)              0         \n",
      " ights)                                                          \n",
      "                                                                 \n",
      " cluster_dense (ClusterWeig  (None, 10)                40578     \n",
      " hts)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40814 (239.07 KB)\n",
      "Trainable params: 20426 (79.79 KB)\n",
      "Non-trainable params: 20388 (159.28 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 8,\n",
    "  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS\n",
    "}\n",
    "\n",
    "# Cluster a whole model\n",
    "clustered_model = cluster_weights(model, **clustering_params)\n",
    "\n",
    "# Use smaller learning rate for fine-tuning clustered model\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "clustered_model.compile(\n",
    "  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "clustered_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38150e32-d7ae-41e0-b973-3ad278c99c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model Profile                    | Value         | Unit    |\n",
      "|----------------------------------|---------------|---------|\n",
      "| Selected GPUs                    | None Detected | GPU IDs |\n",
      "| No. of FLOPs                     | 0.0           | BFLOPs  |\n",
      "| GPU Memory Requirement           | 0.0062        | GB      |\n",
      "| Model Parameters                 | 0.0408        | Million |\n",
      "| Memory Required by Model Weights | 0.1557        | MB      |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 11:35:21.723535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-03 11:35:21.724926: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "print(model_profiler(clustered_model, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c52eeba2-9ca7-48f1-9e51-3cfaba57d487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 3s 19ms/step - loss: 0.0901 - accuracy: 0.9685 - val_loss: 0.0983 - val_accuracy: 0.9698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x79340136a220>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune model\n",
    "clustered_model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  batch_size=500,\n",
    "  epochs=1,\n",
    "  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f1601be-faef-4639-99c9-ed112cbf3ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9818000197410583\n",
      "Clustered test accuracy: 0.9664000272750854\n"
     ]
    }
   ],
   "source": [
    "_, clustered_model_accuracy = clustered_model.evaluate(\n",
    "  test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Clustered test accuracy:', clustered_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6f85b5f-0727-423d-95c8-248ca0e873a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d/bias:0 [-0.00880162 -0.16140667 -0.00986281 -0.14170563 -0.5053878  -0.29706922\n",
      " -0.42732382 -0.00310488  0.2989068  -0.26112655 -0.05702841 -0.19512722]\n",
      "conv2d/kernel:0 [[[[ 0.6414186   0.4315604  -0.83917344  0.07032441  0.06383375\n",
      "    -0.46468544  0.37808985  0.81573415 -0.04537372  0.2775053\n",
      "    -1.0989255   0.15231964]]\n",
      "\n",
      "  [[ 0.91263103  0.26947066 -0.19430073 -0.70849437  0.23527032\n",
      "     0.3681798   0.3481814   0.52590793  0.31527635  0.29899448\n",
      "    -0.8427733   0.13663164]]\n",
      "\n",
      "  [[ 0.9289561  -1.0877162   0.07902098 -0.9345826   0.3765564\n",
      "     0.42265028 -0.07603849 -1.0387789  -0.77800494 -0.4469227\n",
      "    -0.14842184 -0.09797344]]]\n",
      "\n",
      "\n",
      " [[[-0.29818738  0.79128516 -0.51785403  0.79342765  0.0726191\n",
      "     0.38634083 -0.0849975   1.0829166  -0.13798949 -0.30349055\n",
      "    -0.61363727  0.3291322 ]]\n",
      "\n",
      "  [[ 0.39976525  0.1917658   0.01268764  0.05215013  0.14208715\n",
      "     0.406272   -0.14213848  0.17550245 -0.55062205  0.42207795\n",
      "     0.6344701   0.49010646]]\n",
      "\n",
      "  [[ 0.5656159  -1.1639744  -0.02803619 -0.20617461 -0.2732856\n",
      "    -0.35507977 -0.19504906 -1.2392557  -0.2869749   0.08582735\n",
      "     0.86644673  0.19855238]]]\n",
      "\n",
      "\n",
      " [[[-1.4547379   0.7448644   0.73655385  0.4447807   0.2971123\n",
      "     0.32442117 -0.13364176 -0.03495368 -0.59903157 -0.5916125\n",
      "    -0.11815778 -0.8681341 ]]\n",
      "\n",
      "  [[-1.622264    0.28021818  0.7799112   0.33838478  0.18286906\n",
      "    -0.2734495   0.28499183 -1.5304242  -0.23497593  0.4169306\n",
      "     0.3822007  -0.43750417]]\n",
      "\n",
      "  [[-1.4120517  -0.5725914  -0.18922214  0.2497899   0.00708158\n",
      "    -0.29583135  0.45106205 -1.2291358   0.01199278  0.14137773\n",
      "    -0.00281972  0.5832647 ]]]]\n",
      "cluster_conv2d/cluster_centroids_kernel:0 [-0.11839788 -1.1639384   0.431496   -0.7084927   0.92725855  0.17377327\n",
      " -1.6222799  -0.35508907]\n",
      "cluster_conv2d/pulling_indices_kernel:0 [[[[2 2 3 5 5 7 2 4 0 5 1 5]]\n",
      "\n",
      "  [[4 5 0 3 5 2 2 2 2 5 3 5]]\n",
      "\n",
      "  [[4 1 5 3 2 2 0 1 3 7 0 0]]]\n",
      "\n",
      "\n",
      " [[[7 4 7 4 5 2 0 4 0 7 3 2]]\n",
      "\n",
      "  [[2 5 0 5 5 2 0 5 3 2 2 2]]\n",
      "\n",
      "  [[2 1 0 0 7 7 0 1 7 5 4 5]]]\n",
      "\n",
      "\n",
      " [[[6 4 4 2 5 2 0 0 3 3 0 3]]\n",
      "\n",
      "  [[6 5 4 2 5 7 5 6 0 2 2 7]]\n",
      "\n",
      "  [[6 3 0 5 0 7 2 1 0 5 0 2]]]]\n",
      "dense/bias:0 [ 0.01885895  0.14387855  0.0113225  -0.04226584 -0.05123937  0.04159597\n",
      " -0.0129024   0.02650014 -0.06818855 -0.02737546]\n",
      "dense/kernel:0 [[ 1.4008361e-01  2.5361079e-01 -4.3695351e-01 ...  2.2502510e-01\n",
      "  -3.9156973e-02  2.7141213e-01]\n",
      " [-4.2864278e-02  3.4079474e-04  5.2614056e-02 ...  3.5158657e-02\n",
      "  -1.1227222e-01 -4.8721578e-02]\n",
      " [ 3.2207948e-01  3.0527863e-01 -4.2667672e-01 ...  1.2797336e-01\n",
      "  -1.7028368e-01  3.3041781e-01]\n",
      " ...\n",
      " [-9.9831179e-02 -1.4935359e-01  1.7469861e-01 ... -1.1072156e-01\n",
      "  -1.3589330e-01 -8.0372825e-02]\n",
      " [ 2.4848150e-02  3.0155692e-01 -1.9966803e-01 ...  9.0629011e-02\n",
      "   3.1457122e-02  4.2221617e-02]\n",
      " [-7.2725169e-02 -1.2868422e-01 -5.6526687e-02 ... -5.8910530e-02\n",
      "  -1.9420879e-01 -1.3993889e-01]]\n",
      "cluster_dense/cluster_centroids_kernel:0 [ 0.04533177 -0.54788417 -0.27342182  0.30646104 -0.05988504 -0.13564509\n",
      "  0.15892088 -0.82711834]\n",
      "cluster_dense/pulling_indices_kernel:0 [[6 3 1 ... 6 4 3]\n",
      " [4 0 0 ... 0 5 4]\n",
      " [3 3 1 ... 6 5 3]\n",
      " ...\n",
      " [5 5 6 ... 5 5 4]\n",
      " [0 3 5 ... 0 0 0]\n",
      " [4 5 4 ... 4 5 5]]\n"
     ]
    }
   ],
   "source": [
    "for w in clustered_model.weights:\n",
    "    print(w.name, w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f12110d9-f085-48b0-bb1d-3e8b770eb59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving clustered model to:  /src/final.h5\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/217805229.py:6: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  keras.models.save_model(final_model, clustered_keras_file,\n"
     ]
    }
   ],
   "source": [
    "final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "\n",
    "# _, clustered_keras_file = tempfile.mkstemp('.h5')\n",
    "clustered_keras_file = \"/src/final.h5\"\n",
    "print('Saving clustered model to: ', clustered_keras_file)\n",
    "keras.models.save_model(final_model, clustered_keras_file, \n",
    "                           include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a53acbcb-3ce2-4ad8-b9c5-5b2f593891cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel:0 [[[[ 0.44195125 -0.44239596 -1.1691003   0.05833105  0.05833105\n",
      "     0.05833105  0.44195125 -0.44239596 -0.44239596  0.05833105\n",
      "    -0.44239596 -0.24850494]]\n",
      "\n",
      "  [[ 0.44195125 -0.81556934 -0.24850494  0.05833105  0.05833105\n",
      "     0.05833105  0.6861731   0.23193341 -1.1691003   0.6861731\n",
      "     0.23193341  0.05833105]]\n",
      "\n",
      "  [[-1.1691003  -1.1691003   0.6861731   0.23193341 -0.24850494\n",
      "     0.23193341  0.6861731   0.23193341 -0.44239596  0.6861731\n",
      "     0.23193341  0.44195125]]]\n",
      "\n",
      "\n",
      " [[[ 0.44195125  0.6861731  -1.1691003   0.23193341  0.44195125\n",
      "     0.23193341  0.44195125  0.05833105 -0.81556934 -0.44239596\n",
      "     0.23193341  0.05833105]]\n",
      "\n",
      "  [[ 0.44195125  0.05833105  0.44195125  0.23193341  0.44195125\n",
      "     0.05833105  0.44195125  0.44195125  0.05833105  0.23193341\n",
      "     0.23193341  0.23193341]]\n",
      "\n",
      "  [[-0.81556934 -0.44239596  0.6861731   0.05833105  0.23193341\n",
      "    -0.24850494 -0.44239596 -0.24850494  0.6861731   0.44195125\n",
      "     0.05833105  0.05833105]]]\n",
      "\n",
      "\n",
      " [[[ 0.23193341  0.23193341 -0.44239596  0.05833105 -0.44239596\n",
      "    -0.24850494 -1.1691003   0.23193341 -1.1691003  -1.1691003\n",
      "     0.23193341  0.05833105]]\n",
      "\n",
      "  [[ 0.44195125  0.6861731   0.6861731   0.05833105 -0.24850494\n",
      "    -0.24850494 -1.1691003   0.05833105  0.05833105 -1.1691003\n",
      "     0.05833105  0.05833105]]\n",
      "\n",
      "  [[-0.24850494  0.6861731   0.23193341 -0.24850494  0.44195125\n",
      "     0.23193341 -1.1691003  -0.44239596  0.44195125 -0.44239596\n",
      "    -0.44239596  0.05833105]]]]\n",
      "bias:0 [-0.1729776  -0.01469374 -0.02593785 -0.28410992 -0.22589289 -0.1728474\n",
      " -0.00106896 -0.17225793  0.24345168 -0.01064291 -0.19606835 -0.34694782]\n",
      "kernel:0 [[ 0.02004033  0.02004033  0.02004033 ...  0.02004033 -0.05470961\n",
      "  -0.05470961]\n",
      " [ 0.13187665  0.13187665 -0.16312122 ...  0.13187665 -0.16312122\n",
      "   0.02004033]\n",
      " [ 0.13187665  0.02004033  0.02004033 ... -0.05470961  0.02004033\n",
      "  -0.05470961]\n",
      " ...\n",
      " [ 0.02004033  0.02004033  0.13187665 ...  0.02004033 -0.16312122\n",
      "  -0.16312122]\n",
      " [-0.05470961 -0.05470961  0.02004033 ...  0.02004033 -0.05470961\n",
      "  -0.05470961]\n",
      " [ 0.02004033  0.02004033  0.02004033 ...  0.02004033 -0.05470961\n",
      "  -0.05470961]]\n",
      "bias:0 [-0.0018288   0.13438939  0.01521314 -0.04910447 -0.05581468  0.05860844\n",
      " -0.01452328  0.03936254 -0.09280131 -0.00629712]\n"
     ]
    }
   ],
   "source": [
    "for w in final_model.weights:\n",
    "    print(w.name, w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d827f5b-a51a-4be3-8c34-b2c976b08b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model Profile                    | Value         | Unit    |\n",
      "|----------------------------------|---------------|---------|\n",
      "| Selected GPUs                    | None Detected | GPU IDs |\n",
      "| No. of FLOPs                     | 0.0           | BFLOPs  |\n",
      "| GPU Memory Requirement           | 0.0062        | GB      |\n",
      "| Model Parameters                 | 0.0204        | Million |\n",
      "| Memory Required by Model Weights | 0.0779        | MB      |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 17:17:12.361598: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-02 17:17:12.367716: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "print(model_profiler(final_model, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c16d479-3494-49f2-b0a0-319a46d8dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centroids = tf.linspace(-1.0, 1.0, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6a338a9-bb1d-4333-b64c-309c473805e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([-1.        , -0.3333333 ,  0.33333337,  1.        ], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c570cf2-df5f-430f-b90a-f811712242b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # It returns the size of the gzipped model in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "594281f9-3315-4f53-a5c8-0065060766f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 78217.00 bytes\n",
      "Size of gzipped clustered Keras model: 12581.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped clustered Keras model: %.2f bytes\" % (get_gzipped_model_size(clustered_keras_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868ec95a-c887-4895-9efe-8971fbc2dcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
