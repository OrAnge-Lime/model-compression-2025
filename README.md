# model-compression-2025

Репозиторий курса по сжатию и ускорению моделей машинного обучения.
ИТМО 2025, направление магистратуры Искуственный интеллект.


*План курса*

    Пара 3 - Кластеризация весов моделей.
        1. Что такое кластеризация весов?
            - Идея: заменить уникальные веса модели на меньший набор центроидов.
            - Чем-то похоже на квантизацию, но с более сложной обработкой.
            - Сильнее сжимает, но требует дополнительной декомпрессии на инференсе.
	    2.	Как работает кластеризация?
	        - Использование k-means для группировки весов.
	        - Заменяем веса центроидами, храним индексы.
	        - Гибридный подход: кластеризация + квантизация.
	    3.	Где применяется?
	        - Чаще встречается в CV (сверточные сети, MobileNet).
	        - В NLP используется реже из-за потери точности и высокого влияния на активации.
	        - Возможные кейсы для NLP: кластеризация в self-attention блоках.
	    5.	Инструменты для кластеризации
	        - torch.nn.utils.prune + k-means.
	        - TensorFlow Model Optimization Toolkit (TFMOT).
        6. Практика
            1. Готовим окружение
	        2.	Применяем кластеризацию к весам
	            - Запускаем k-means на слоях модели.
	            - Создаём матрицу центроидов и индексов.
	        3.	Оцениваем влияние на производительность
	            - Время инференса до/после.
	            - Изменение памяти (RAM/VRAM).
	            - Насколько ухудшилось качество (accuracy, PPL).
	        4.	Сравнение с квантизацией
	            - В каких случаях кластеризация даёт лучший результат.
	            - Можно ли комбинировать методы?
	        5.	Записываем результаты в таблицу
	        6.	Домашнее задание
	            Попробовать самостоятельно реализовать кластеризацию весов для своей модели.
                Резльтаты занести в таблицу и скинуть pull request с результатами и код кластеризации в ветку занятия

### Презентации
[Занятие 3 Кластеризация](https://docs.google.com/presentation/d/1Cjqeu4SxZuUteqSc6xaUMOePWA2H2hdpANJ5_p7kFB8/edit#slide=id.g1e7daee4ab9_0_116)
[Статья про метод кластеризации](https://arxiv.org/pdf/1510.00149)


### Таблица сравнения методов компрессии моделей

| Модель                | Метод                         | Время инференса (CPU, ms) | Время инференса (GPU, ms) | Использование RAM (MB) | Использование VRAM (MB) | Качество (CER, WER)        | Размер в .gz (MB) |
| :-------------------- | :---------------------------: | :-----------------------: | :-----------------------: | :--------------------: | :----------------------: | :-------------------------: | :---------------: |
| openai/whisper-small  | Оригинальная модель           | 3601.86                   | 477.27                    | 29.71                  | 1053.03                  | 1.32% CER, 3.66% WER        | 535.87            |
| openai/whisper-small  | Кластеризированная модель     | 3741.66                   | 475.24                    | 8.50                   | 1053.03                  | 1.37% CER, 3.82% WER        | 321.95            |


Есть небольшая проблема с замером RAM, но по факту в процессе мониторинга никакой разницы по занимаемой памяти между моделями выявлено не было